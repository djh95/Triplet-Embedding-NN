{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1a6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TripletLossFunc import TripletLossFunc\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from Utils import *\n",
    "from Define import *\n",
    "from NUS_WIDE_Helper import *\n",
    "\n",
    "from jupyterplot import ProgressPlot\n",
    "from tqdm.notebook import tqdm\n",
    "from TenNetImage import *\n",
    "from TenNetTag import *\n",
    "from TagDecoder import *\n",
    "import TenNetModel as TenNet\n",
    "import TenDecoderModel as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfad4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "getTenNetFromFile = False\n",
    "getDecoderFromFile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2754758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUS_WIDE\n",
    "train_data = NUS_WIDE_Helper(DataSetType.Train_81,)\n",
    "valid_data = NUS_WIDE_Helper(DataSetType.Test_81,  Number_Of_Images_Valid)\n",
    "#test_data = NUS_WIDE_Helper(DataSetType.Test_81)\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "#test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_model = models.vgg16(pretrained=True).to(device)\n",
    "image_model = TenNet_Image().to(device)\n",
    "tag_model = TenNet_Tag(train_data.get_tag_list()).to(device)\n",
    "\n",
    "optim = torch.optim.Adam([{'params' : image_model.parameters()}, {'params' : tag_model.parameters()}], lr=0.001)\n",
    "triplet_loss = TripletLossFunc(Margin_Distance)\n",
    "\n",
    "max_v = Margin_Distance * 10\n",
    "n_epochs = N_Epochs\n",
    "Lambda = 0.3\n",
    "min_valid_loss = -1\n",
    "ten_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if getTenNetFromFile:\n",
    "    TenNet.getTenModel(tag_model, image_model, name = \"best_val.ckpt\")\n",
    "else:\n",
    "    pp = ProgressPlot(plot_names=[\"loss\", \"train distance\"],\n",
    "                      line_names=[\"train/pos_IT\", \"valid/pos_II\", \"0/neg_IT\", \"0/neg_II\"],\n",
    "                      x_lim=[0, n_epochs-1], \n",
    "                      y_lim=[0, max_v])\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    for e in pbar:\n",
    "    \n",
    "        loss_dis_train =  TenNet.train(image_model, tag_model, train_loader, triplet_loss, Lambda, optim)\n",
    "        TenNet.output_loss_dis(f\"epoch:{e}: 1-train dataset with train model\", loss_dis_train)\n",
    "        \n",
    "        loss_dis_valid = TenNet.evalue(image_model, tag_model, valid_loader, triplet_loss, Lambda, optim, e, min_valid_loss, True)   \n",
    "        TenNet.output_loss_dis(f\"epoch:{e}: 2-valid dataset with evalue model\", loss_dis_valid)\n",
    "        min_valid_loss = loss_dis_valid[5]\n",
    "    \n",
    "        ten_res.append([loss_dis_train,loss_dis_valid])\n",
    "        TenNet.updataProgressPlot(pp, loss_dis_train, loss_dis_valid, max_v)\n",
    "    \n",
    "    pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "TenNet.printResult(ten_res, n_epochs, max_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2ba40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ceea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model = D.TagDecoder(train_data.get_tag_num()).to(device)\n",
    "\n",
    "optim = torch.optim.Adam(predict_model.parameters(), lr=0.001)\n",
    "loss_funk = F.pairwise_distance \n",
    "\n",
    "n_epochs = N_Epochs_Decoder\n",
    "max_accuracy = -1\n",
    "threshold = 0.5\n",
    "decoder_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0bef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if getDecoderFromFile:\n",
    "    getDecoderModel(decoder, name = \"decoder_best_val.ckpt\")\n",
    "else:\n",
    "    pp = ProgressPlot(plot_names=[\"loss\", \"mean num of tags\", \"accuracy\"], \n",
    "                      line_names=[\"train/correct\", \"valid/total\"],\n",
    "                      x_lim=[0, n_epochs-1], \n",
    "                      y_lim=[[0,50], [0,20], [0,1]])\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "\n",
    "    for e in pbar:\n",
    "    \n",
    "        loss_num_train = D.train(predict_model, tag_model, image_model, train_loader, loss_funk, optim, threshold)\n",
    "        D.output_loss_num(f\"epoch:{e}: 1-train dataset with train model\", loss_num_train)\n",
    "        \n",
    "        loss_num_valid = D.predict(predict_model, tag_model, image_model, valid_loader, loss_funk, optim, threshold, True, max_accuracy, e)   \n",
    "        D.output_loss_num(f\"epoch:{e}: 2-valid dataset with evalue model\", loss_num_valid)\n",
    "        max_accuracy = loss_num_valid[4]\n",
    "    \n",
    "        decoder_res.append([loss_num_train,loss_num_valid])\n",
    "    \n",
    "        updataProgressPlot(pp, loss_num_train, loss_num_valid)\n",
    "      \n",
    "    pp.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bda6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.printResult(decoder_res, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87742550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd7cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = train_loader\n",
    "for (x_images,y_tags) in loader:\n",
    "    x_images, y_tags = x_images.to(device), y_tags.to(device)    \n",
    "    image_features = image_model(x_images)\n",
    "    tag_features = tag_model(y_tags)\n",
    "        \n",
    "    # in feature space\n",
    "    IT_dist =  F.pairwise_distance(image_features, tag_features)\n",
    "\n",
    "    # first triplet loss, an image, cor tag, and a neg image\n",
    "    anchor_image = image_features\n",
    "    positive_tag = tag_features\n",
    "\n",
    "    similarity_matrix = get_similarity_matrix(y_tags)\n",
    "    z_tag_indexes = get_one_neighbor(tag_features, similarity_matrix, IT_dist + Margin_Distance)\n",
    "    negative_tag = torch.cat([tag_features[i].view(1,-1) for i in z_tag_indexes])\n",
    "\n",
    "    z_images_pos, z_images_neg = get_pos_neg(y_tags, similarity_matrix)\n",
    "    positive_image = torch.cat([image_features[i].view(1,-1) for i in z_images_pos])\n",
    "    negative_image = torch.cat([image_features[i].view(1,-1) for i in z_images_neg])\n",
    "\n",
    "    lossIT, dist_image_tag_pos, dist_image_tag_neg = triplet_loss(anchor_image, positive_tag, negative_tag)\n",
    "\n",
    "    # second triplet loss, an image, a pos image, a neg image\n",
    "    lossII, dist_image_image_pos, dist_image_image_neg =triplet_loss(anchor_image, positive_image, negative_image)\n",
    "    loss = lossIT +  Lambda * lossII\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z_images_pos, z_images_neg)\n",
    "print(tag_features[0])\n",
    "print(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e12f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f995917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87de29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfbc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62ca5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0988084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
